{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10106703,"sourceType":"datasetVersion","datasetId":6234430},{"sourceId":10172170,"sourceType":"datasetVersion","datasetId":6282502},{"sourceId":10179691,"sourceType":"datasetVersion","datasetId":6287980}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport re\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:41.528275Z","iopub.execute_input":"2024-12-14T11:13:41.528724Z","iopub.status.idle":"2024-12-14T11:13:41.966991Z","shell.execute_reply.started":"2024-12-14T11:13:41.528672Z","shell.execute_reply":"2024-12-14T11:13:41.965726Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install pyicu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:41.968710Z","iopub.execute_input":"2024-12-14T11:13:41.969384Z","iopub.status.idle":"2024-12-14T11:13:52.696034Z","shell.execute_reply.started":"2024-12-14T11:13:41.969328Z","shell.execute_reply":"2024-12-14T11:13:52.694416Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyicu in /opt/conda/lib/python3.10/site-packages (2.14)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import icu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.699800Z","iopub.execute_input":"2024-12-14T11:13:52.700269Z","iopub.status.idle":"2024-12-14T11:13:52.734499Z","shell.execute_reply.started":"2024-12-14T11:13:52.700206Z","shell.execute_reply":"2024-12-14T11:13:52.733096Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Split into 3 samples","metadata":{}},{"cell_type":"code","source":"def split_into_samples(input_file, set_name):\n    df = pd.read_csv(input_file, sep='\\t', encoding='utf-8-sig')\n    samples = np.array_split(df, 3)\n    \n    for i, sample in enumerate(samples, 1):\n        sample.to_csv(f'/kaggle/working/{set_name}_sample_{i}.tsv', sep='\\t', encoding='utf-8-sig', index=False)\n        print(f'Saved {set_name}_sample_{i}.tsv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.736193Z","iopub.execute_input":"2024-12-14T11:13:52.736747Z","iopub.status.idle":"2024-12-14T11:13:52.745625Z","shell.execute_reply.started":"2024-12-14T11:13:52.736689Z","shell.execute_reply":"2024-12-14T11:13:52.744090Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Lọc tags","metadata":{}},{"cell_type":"code","source":"def filter_tags(df):\n    content_lower = df['content'].replace('_', ' ').lower()\n    tags_lower = [tag.lower() for tag in df['tags'].split(',')]\n    filtered_tags_lower = [tag for tag in tags_lower if tag in content_lower]\n\n    original_tags = df['tags'].split(',')\n    tag_map = {tag.lower(): tag for tag in original_tags}\n\n    filtered_tags = [tag_map[tag] for tag in filtered_tags_lower]\n\n    return ','.join(filtered_tags)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.747553Z","iopub.execute_input":"2024-12-14T11:13:52.748042Z","iopub.status.idle":"2024-12-14T11:13:52.769864Z","shell.execute_reply.started":"2024-12-14T11:13:52.747991Z","shell.execute_reply":"2024-12-14T11:13:52.768263Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def get_df_after_filter_tag(df):\n    df.columns = ['content', 'tags']\n    df['content'] = df['content'].fillna('')\n    df['tags'] = df['tags'].fillna('')\n    \n    df['tags'] = df.apply(filter_tags, axis=1)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.772139Z","iopub.execute_input":"2024-12-14T11:13:52.772666Z","iopub.status.idle":"2024-12-14T11:13:52.787687Z","shell.execute_reply.started":"2024-12-14T11:13:52.772613Z","shell.execute_reply":"2024-12-14T11:13:52.786625Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Xử lý dữ liệu","metadata":{"id":"E9xRvhG3JoSY"}},{"cell_type":"markdown","source":"## Lọc nhiễu lần 1","metadata":{"id":"b1blDKdGk4lR"}},{"cell_type":"code","source":"patterns = {\n    'date': r'\\b(?:0[1-9]|[12][0-9]|3[01])/(?:0[1-9]|1[0-2])/\\d{4}\\b|\\b(?:0[1-9]|1[0-2])/(?:0[1-9]|[12][0-9]|3[01])/\\d{4}\\b',\n    'long_numbers': r'\\b\\d{6,}(?:[.,]\\d{3})*\\b(?![A-Za-z])',\n    'ip': r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b|\\b(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}\\b',\n    'percentage': r'\\d+%',\n    'time': r'\\b\\d{1,2}h(?:\\d{2})?\\b|\\b\\d{1,2}:\\d{2}\\b|\\b\\d{1,2}\\+\\d{1,2}\\b',\n    'comments': r'(Ảnh|Nguồn)\\s*:\\s*(?:@\\s*)?\\w+',\n    'mail' : r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b',\n    'url' : r'https?://(?:www\\.)?\\S+|www\\.\\S+|\\b\\S+\\.(?:com|org|net|gov|edu|vn)\\b'\n}","metadata":{"id":"Blsu1zbhlO9H","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.788967Z","iopub.execute_input":"2024-12-14T11:13:52.789328Z","iopub.status.idle":"2024-12-14T11:13:52.805245Z","shell.execute_reply.started":"2024-12-14T11:13:52.789274Z","shell.execute_reply":"2024-12-14T11:13:52.803732Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def remove_patterns(text, patterns):\n    for pattern in patterns.values():\n        text = re.sub(pattern, '', text)\n    return text\n\ndef filter_noise_first(df, set_name):\n    content_list = df['content'].tolist()\n    cleaned_content_list = df['content'].apply(lambda x: remove_patterns(x, patterns))\n    \n    if set_name == 'train':\n        tags_list = df['tags'].tolist()\n        cleaned_df = pd.DataFrame({'content': content_list, 'tags': tags_list})\n    else:\n        cleaned_df = pd.DataFrame({'content': content_list})\n\n    return cleaned_df","metadata":{"id":"F9cNVniRlTlz","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.807244Z","iopub.execute_input":"2024-12-14T11:13:52.807808Z","iopub.status.idle":"2024-12-14T11:13:52.823049Z","shell.execute_reply.started":"2024-12-14T11:13:52.807749Z","shell.execute_reply":"2024-12-14T11:13:52.821735Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Lọc nhiễu lần 2 (Trừ '-' và '/')","metadata":{}},{"cell_type":"code","source":"def remove_special_char(text):\n    # Loại bỏ khoảng trắng trước các dấu\n    text = re.sub(r'\\s+([!#$%&’()*+\\\\<=>?@\\[\\]^`{|}~\\“\\”\\\":.,;])', r'\\1', text)\n\n    # Xoá ký tự đặc biệt, ngoại trừ '-' và '/'\n    special_char = \"!#$%&’()*+<=>?@[]^`{|}~“”\\\":±'\"\n    translation_table = str.maketrans(special_char, \" \" * len(special_char))\n    text = text.translate(translation_table)\n\n    # Loại bỏ ký tự '/' và '-' nếu không có ký tự liền trước và liền sau\n    text = re.sub(r'(?<!\\w)[/-](?!\\w)', '', text)\n\n    # Loại bỏ khoảng trắng dư thừa do ký tự bị cách\n    text = re.sub(r'\\s{2,}', ' ', text)\n\n    # Loại bỏ nhiều dấu chấm\n    text = re.sub(r'\\.', '', text)\n    text = re.sub(r'…', '', text)\n\n    # Xóa khoảng trắng thừa ở đầu và cuối câu\n    return text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.824920Z","iopub.execute_input":"2024-12-14T11:13:52.825436Z","iopub.status.idle":"2024-12-14T11:13:52.845692Z","shell.execute_reply.started":"2024-12-14T11:13:52.825378Z","shell.execute_reply":"2024-12-14T11:13:52.844366Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Xử lý thành ngữ","metadata":{"id":"J4iGnZZgm4UZ"}},{"cell_type":"markdown","source":"### Tiền xử lý thành ngữ","metadata":{"id":"gFWCowiXnv_M"}},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    \n    text = re.sub(r'[^\\w\\s]+$', '', text)\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\d+', '', text)\n    text = re.sub(r'[\\[\\]]', '', text)\n    \n    text = re.sub(r'[\\u4e00-\\u9fff]+', '', text)  # loại bỏ tiếng Trung\n    \n    return text\n\ndef create_idiom_dict(tntn_web_num):\n    df = pd.read_csv(f'/kaggle/input/idiom-org/tntn_{tntn_web_num}.csv')\n    \n    df = df.map(lambda x: clean_text(x) if isinstance(x, str) else x)\n    \n    df = pd.concat([df, df], ignore_index=True)\n    \n    df = df.drop_duplicates()\n    \n    return df","metadata":{"id":"SYv8kvJFno83","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.847068Z","iopub.execute_input":"2024-12-14T11:13:52.847487Z","iopub.status.idle":"2024-12-14T11:13:52.864006Z","shell.execute_reply.started":"2024-12-14T11:13:52.847451Z","shell.execute_reply":"2024-12-14T11:13:52.862450Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# tạo từ điển\n\nidiom_df_all = pd.DataFrame()\n\nfor tntn_web_num in range(1, 5):\n  idiom_df_all = create_idiom_dict(tntn_web_num)\n\n# thêm tay một số trường hợp đặc biệt\nnew_tntn = [\"lụa đẹp vì người\", \"không cánh mà bay\", \"không ít thì nhiều\"]\nidiom_df_new = pd.DataFrame(new_tntn, columns=[idiom_df_all.columns[0]])\nidiom_df_all = pd.concat([idiom_df_all, idiom_df_new], ignore_index=True)\n\n# sort theo tiếng Việt\ncollator = icu.Collator.createInstance(icu.Locale('vi', 'VN'))\n\ndf_sorted = idiom_df_all.sort_values(by=idiom_df_all.columns[0], key=lambda x: x.apply(lambda name: collator.getSortKey(name)))\ndf_sorted.reset_index(drop=True, inplace=True)\n\n# set thanh ngu!!\nidiom_set = set(df_sorted['Thành ngữ/Tục ngữ'].str.lower())","metadata":{"id":"vvpwEZVMntwA","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.865883Z","iopub.execute_input":"2024-12-14T11:13:52.866300Z","iopub.status.idle":"2024-12-14T11:13:52.929650Z","shell.execute_reply.started":"2024-12-14T11:13:52.866258Z","shell.execute_reply":"2024-12-14T11:13:52.928229Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### Tách thành ngữ trong data theo từ điển\n","metadata":{"id":"klRxLWvvnzwZ"}},{"cell_type":"code","source":"def tokenizer(text):\n    modified_text = text\n    \n    for idiom in idiom_set:\n        pattern = r'\\b' + re.escape(idiom) + r'\\b'\n        if re.search(pattern, modified_text.lower()):\n            modified_text = re.sub(pattern, lambda m: m.group(0).replace(\" \", \"_\"), modified_text, flags=re.IGNORECASE)\n\n    return modified_text\n\ndef process_paragraph(paragraph):\n    sents = paragraph.split('. ')\n    cleaned_sents = [tokenizer(sent) for sent in sents]\n    return '. '.join(cleaned_sents)\n\ndef process_paragraphs(content_list):\n    return [process_paragraph(p) for p in tqdm(content_list, desc=\"Processing paragraphs\")]\n\ndef idiom_process(df, set_name):\n    content_list = df['content'].tolist()\n    idiom_content_list = process_paragraphs(content_list)\n\n    if set_name == 'train':\n        tags_list = df['tags'].tolist()\n        cleaned_df = pd.DataFrame({'content': idiom_content_list, 'tags': tags_list})\n    else:\n        cleaned_df = pd.DataFrame({'content': idiom_content_list})\n    \n    return cleaned_df","metadata":{"id":"3gQDs3tkn7pz","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.930914Z","iopub.execute_input":"2024-12-14T11:13:52.931259Z","iopub.status.idle":"2024-12-14T11:13:52.940500Z","shell.execute_reply.started":"2024-12-14T11:13:52.931194Z","shell.execute_reply":"2024-12-14T11:13:52.939309Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"def preprocess(df, sample_num, set_name):\n    output_path = f'/kaggle/working/{set_name}_preprocessing1_{sample_num}.csv'\n\n    # Xác định giá trị bắt đầu cho `idx`\n    if sample_num == 1:\n        if set_name == 'test':\n            start_idx = 0\n        else:\n            test_file_path = '/kaggle/working/test_preprocessing1_3.csv'\n\n            test_df = pd.read_csv(test_file_path)\n            start_idx = test_df['idx'].max() + 1\n    else:\n        prev_output_path = f'/kaggle/working/{set_name}_preprocessing1_{sample_num - 1}.csv'\n        prev_df = pd.read_csv(prev_output_path)\n        if 'idx' in prev_df.columns:\n            start_idx = prev_df['idx'].max() + 1\n\n    if set_name == 'train':\n        df = get_df_after_filter_tag(df)\n    \n    df = filter_noise_first(df, set_name)\n    df['content'] = df['content'].apply(remove_special_char)\n    df = idiom_process(df, set_name)\n    \n    df['idx'] = range(start_idx, start_idx + len(df))\n\n    cols = ['idx'] + [col for col in df.columns if col != 'idx']\n    df = df[cols]\n\n    df.to_csv(output_path, index=False, encoding='utf-8-sig')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.941932Z","iopub.execute_input":"2024-12-14T11:13:52.942315Z","iopub.status.idle":"2024-12-14T11:13:52.956892Z","shell.execute_reply.started":"2024-12-14T11:13:52.942281Z","shell.execute_reply":"2024-12-14T11:13:52.955647Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Chạy","metadata":{}},{"cell_type":"code","source":"set_names = [\"test\", \"train\"]\n\nfor set_name in set_names:\n    print(f\"Processing for set_name: {set_name}\")\n    if set_name == \"test\":\n        split_into_samples('/kaggle/input/org-test-data/articles_testing.tsv', set_name)\n    else:\n        split_into_samples('/kaggle/input/original-articles/articles_training.tsv', set_name)\n\n    for sample_num in range(1, 4): \n        df = pd.read_csv(f'/kaggle/working/{set_name}_sample_{sample_num}.tsv', sep='\\t', encoding='utf-8-sig')\n        preprocess(df, sample_num, set_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T11:13:52.961118Z","iopub.execute_input":"2024-12-14T11:13:52.961534Z","iopub.status.idle":"2024-12-14T11:40:14.160455Z","shell.execute_reply.started":"2024-12-14T11:13:52.961498Z","shell.execute_reply":"2024-12-14T11:40:14.159301Z"}},"outputs":[{"name":"stdout","text":"Processing for set_name: test\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"},{"name":"stdout","text":"Saved test_sample_1.tsv\nSaved test_sample_2.tsv\nSaved test_sample_3.tsv\n","output_type":"stream"},{"name":"stderr","text":"Processing paragraphs: 100%|██████████| 14635/14635 [01:43<00:00, 141.76it/s]\nProcessing paragraphs: 100%|██████████| 14634/14634 [01:44<00:00, 139.40it/s]\nProcessing paragraphs: 100%|██████████| 14634/14634 [01:44<00:00, 140.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing for set_name: train\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"},{"name":"stdout","text":"Saved train_sample_1.tsv\nSaved train_sample_2.tsv\nSaved train_sample_3.tsv\n","output_type":"stream"},{"name":"stderr","text":"Processing paragraphs: 100%|██████████| 33284/33284 [05:27<00:00, 101.69it/s]\nProcessing paragraphs: 100%|██████████| 33283/33283 [05:32<00:00, 100.08it/s]\nProcessing paragraphs: 100%|██████████| 33283/33283 [05:27<00:00, 101.69it/s]\n","output_type":"stream"}],"execution_count":14}]}